{
  "resume": {
    "path": "JinglongXiong_resume_ml.pdf",
    "text_length": 4474
  },
  "parameters": {
    "job_location": "New York",
    "max_jobs": 100000,
    "tfidf_filter_count": 10,
    "final_recommendations": 5
  },
  "tfidf_results": [
    {
      "rank": 1,
      "job_id": 3102,
      "job_title": "Developer - Senior Data Engineer",
      "score": 0.3117075088498998,
      "job_description": "APPLICANTS MUST BE LOCAL TO NYC/NJ/SOUTHERN CONNECTICUT AREA - Driveable distance to NYC.\nJob Summary\nA Developer assists in designing, developing, and supporting applications. These applications include systems developed solely for the web environment as well as development efforts designed to web-enable end-user applications. This individual may also assist in the creation and ongoing management of corporate web sites and intranet communities. The Developer will have a thorough understanding of programming techniques and tools, web development, and system management tools.\nPrinciple Duties\nThe Sr. Data Engineer will play a pivotal role in designing, building and operationalizing data pipelines that feed the enterprise data ecosystem for a variety of multi-faceted analytics created by data consumers. The data engineer needs to guarantee compliance with data governance and data security requirements while creating, improving, and operationalizing integrated and reusable data pipelines. The data engineer will be measured on their ability to create repeatable, efficient, high-quality code, automation-friendly processes, and delivering work products quickly.\nYears Of Experience\nFive (5) years of progressive, responsible experience in the field of data processing, computer systems, and applications.\nOperations Specialty requires supervisory experience (5 years).\nGeneral Responsibilities\nLead construction, maintenance, & optimization of data pipelines.\nDrive Automation through effective metadata management, using innovative and modern tools, techniques, and architectures to improve productivity.\nLead renovation of the data management infrastructure to drive automation in data integration and management.\nCollaborate with multiple Analytics Center of Excellence teams and EIM team in refining their data requirements for various DnA initiatives and data consumption requirements.\nIdentify gaps in new data initiatives and how to address new data requirements.\nTransfer knowledge of data and/or domain understanding in addressing new data requirements.\nPropose appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques to optimize data requirements.\nWork with data governance teams to ensure data scientists and consumers use corresponding data responsibly through data governance and compliance initiatives.\nDesign and implement data quality monitoring systems, which includes source-to-target data validations as well as anomaly detection\nDevelop and understand all features of each a module and their impact on other modules.\nAnalyze and develop understanding of how data flows through the system and apply that knowledge to the current business model.\nIdentify and define system errors and/or deficiencies.\nLiaise with other developers (i.e: software, application, web, etc) to determine best path solutions and manage the priorities through collaboration with internal stakeholders.\nPlan and coordinate testing and implementation of system patches and upgrades leading a cross functional team of power users.\nExtract key business performance metrics.\nAnalyze user needs and software requirements to determine areas of opportunity for increased efficiencies.\nCreate written user documentation, instructions, and procedures for the purpose of training new employees and improving over-all user proficiency.\nEvaluate new technologies for potential implementation including development of business justification and project implementation planning, when appropriate.\nUtilizing in-house or external resources, manage the network and related hardware. Ensure that help-desk tasks are promptly addressed and resolved\nQualifications And Preferred Skills\n\u00e2\u0097? Bachelor's degree/master's degree/advanced degree in computer science, statistics, applied mathematics, data management, information systems, information science or related field\n\u00e2\u0097? Expertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies\n\u00e2\u0097? Preferred experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms\n\u00e2\u0097? Full Lifecycle Data Warehouse, Data Mart Development experience is a big plus.\n\u00e2\u0097? Agile Software development methodologies\n\u00e2\u0097? Preferred experience with any automation tool such as AutoSys, Cntl-M.\n\u00e2\u0097? Proficient in Microsoft Office (Required)\n\u00e2\u0097? Expert in Informatica PowerCenter, PL/SQL, SQL and additional programming languages such as Python, Java etc.\n\u00e2\u0097? Minimum 10 years of work experience in data management disciplines, including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.\n\u00e2\u0097? Minimum 2 years designing and implementing a fully operational production grade large scale data solution on Snowflake Data Warehouse.\n\u00e2\u0097? Minimum 10 years of hands on experience designing and implementing production grade data warehousing solutions on large scale databases such as SQL Server, Oracle or DB2\n\u00e2\u0097? 5+ years data pipeline development experience with Informatica Powercenter and IBM DataStage\n\u00e2\u0097? 3+ years of experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, others\n\u00e2\u0097? 3+ years of experience with Shell/Perl Scripting\n\u00e2\u0097? 5+ years of experience with popular database programming languages including SQL, PL/SQL\n(required), others for relational databases and certifications on upcoming NoSQL/Hadoop oriented databases (preferred) like MongoDB, Cassandra, others for nonrelational databases.\nEducation Level\nA Baccalaureate Degree from an accredited college or university with a major in Computer Science, Systems Engineering, applied Mathematics, Business Administration, Economics/Statistics, Telecommunications, Data Communications, or a related field of study; and\nFive (5) years of progressive, responsible experience in the field of data processing, computer systems, and applications.\nOperations Specialty requires supervisory experience (5 years).\nNetwork Services requires a telecommunications background and experience.\nBroad knowledge and expertise in the characteristics of computers, peripheral devices, communications systems and hardware capabilities, programming languages, E.D.P. applications, systems analysis methodology, data management and retrieval techniques; or\nA satisfactory equivalent combination of training, education, and experience.\nShow more\nShow less"
    },
    {
      "rank": 2,
      "job_id": 11988,
      "job_title": "NLP Team Lead Engineer",
      "score": 0.3069079905319216,
      "job_description": "Are you an experienced NLP Engineer with in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts?\nRYTE, a breakthrough Artificial Intelligence health tech company is looking for an NLP Team Lead Engineer who will contribute to pushing the boundaries of RYTE\u2019s natural language processing capabilities and driving innovation within the company\u2019s linguistic technology initiatives.\nFinding the right physician, selecting the organization providing the most suitable service, and obtaining the most relevant health information, whether in the US or globally, can be complex and filled with uncertainty. Enter RYTE: an AI-driven platform designed to simplify this process. By analyzing data from millions of healthcare providers, experts, medical procedures, clinical outcomes, and a variety of other data points, RYTE offers users a comprehensive view of their options, uniquely tailored to their needs. It offers:\nPersonalized Recommendations: Based on your specific situation, RYTE's platform presents the best healthcare options for you, no matter where you are in the world.\nUnprecedented Insights: With billions of data points on countless medical professionals and facilities, its AI-driven software gives rankings and insights with metrics previously unavailable for decision-making.\nVersatile Applications: Launching for individuals seeking specialized care (B2C), with plans for the Pharmaceutical, Medtech, Health Insurance (B2B), and Doctor (B2D) markets, the RYTE platform caters to diverse needs.\nBehind RYTE is a dedicated team of top physicians, healthcare executives, data scientists, and AI specialists who have been hard at work since 2019. Their mission? To empower everyone, everywhere, with the data-driven insights required to make well-informed healthcare decisions.\nAI Team Lead / Senior NLP Engineer \u2013 Remote to Miami FL (Relocation Assistance Provided)\nBase:\nExtremely competitive\nBonus:\nA generous year-end bonus, based on performance\nBenefits:\nFull benefits, including medical, dental, and vision insurance\nLocation:\nRemote in the USA to start; then relocate to Miami FL in a reasonable time frame\nRelocation assistance:\nExpenses related to relocation will be provided as part of an offer\nPosition:\nFull-Time, Permanent\nRYTE is also hiring individual contributor Senior and Mid-level NLP Engineers, if you are interested please apply here.\nAbout The Role\nAs part of the AI and data engineering department, you will work side by side with a team of AI engineers, architects, and data scientists located in multiple countries (the US, France, and Kazakhstan) to perform research and development on AI-based technologies applied to Healthcare Analytics.\nThe NLP Team Lead Engineer plays a crucial role within the research and development team focused on linguistic technologies. The primary responsibility of this role is to design, develop, and enhance advanced NLP solutions to meet the company\u2019s needs across various domains, working with structured, semi-structured, and non-structured data coming from a wide variety of public and private data sources.\nThe role will be expected to contribute to the design, conception, creation, development, implementation, and testing of different NLP AI algorithms to help measure, map, correlate, disambiguate, and track the quality of RYTE\u2019s rich databases.\nThe Ideal Candidate\nThe ideal candidate will be able to take on a role that is \u201c20% Research / 60% Data Science / 20% MLOps\u201d.\nThe position requires in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts. They are NOT looking for a research scientist, but someone more interested in applying the \u201cstate of the art\u201d approach to long-term projects. You will be processing new data to solve a problem, evaluating the results, selecting an approach within 1-2 weeks, and then shipping your project. Your MLOps skills will be needed to understand the MLOps team\u2019s expectations and properly hand things over.\nWhat You\u2019ll Be Doing \u2013 Day-to-Day\nAs part of the AI and data engineering department, you will work side by side with a team of AI engineers, architects, and data scientists located in multiple countries to perform research and development on AI-based technologies applied to Healthcare Analytics.\nResearch and Development:\nDesign and develop advanced NLP models, such as entity disambiguation, text generation, machine translation, and sentiment analysis that will form the core of our solutions.\nDefine appropriate datasets for language learning.\nExperiment with the latest advancements in NLP research and incorporate them into development projects.\nManage project timelines, milestones, and deliverables autonomously, ensuring timely and successful completion of projects.\nIdentify risks and potential roadblocks, and proactively develop strategies to mitigate them.\nOptimization and Enhancement:\nAnalyze and improve the performance of existing NLP models in terms of accuracy, speed, and efficiency.\nOptimize text processing pipelines to handle large volumes of data.\nCollaboration:\nWork closely with other engineers, data scientists, and researchers to solve complex natural language processing challenges.\nParticipate in meetings and discussions to share ideas, findings, and recommendations with internal stakeholders.\nValidation and Testing:\nDesign testing protocols to evaluate the quality and performance of NLP models.\nTrain the developed model and run evaluation experiments.\nStay updated on the latest trends and advancements in NLP by reading research papers, and tracking relevant open-source projects.\nTeam Leadership and Mentorship:\nProvide guidance, mentorship, and support to the engineering team, fostering a collaborative and innovative work environment.\nOffer constructive feedback, identify areas for improvement, and create personalized development plans.\nDesign and deliver training programs to enhance team members\u2019 technical skills, soft skills, and domain knowledge.\nExperience/Skills\nWhat RYTE is Looking For, In Order of Preference:\nAdvanced expertise in Natural Language Processing, with a deep understanding of language models / LLMs, syntax, semantics, etc.\nProficiency in machine learning techniques, including deep learning frameworks and algorithms (Pytorch, TensorFlow)\nStrong programming skills, preferably in languages such as Python, SQL\nExperience with NLP libraries and tools, like Transformers and Huggingface\nExperience in fine-tuning pre-trained large language models for specific tasks\nCharacter\nStrong communication skills to collaborate with cross-functional teams, able to:\nThis is a low-ego, collaborative environment \u2013 you will learn new things!\nMust be generous, willing to share what you know\nMust be highly motivated to work in a team environment where you both coach and learn from those around you\nOpenness to a multicultural work environment\nHumility, knowing that the field is moving every day and there is always something to learn from others\nEducation/Intelligence\nMaster\u2019s degree (or PhD) in Engineering, Data Science, or Computer Science\nSolid knowledge of data preprocessing, feature engineering, and model evaluation techniques\nExcellent problem-solving skills and the ability to address complex NLP challenges effectively\nCoachability\nMust have a love of learning and an openness to being challenged\nExpect to learn much from your peers & company stakeholders who are experts in their disciplines\nMust be willing to share your knowledge with the team and coach junior team members in the USA/France/Kazakhstan\nThe ideal candidate has a passion for AI, Healthcare, and building something that matters\nWhy new role:\nRYTE is expanding its technical teams rapidly in various geographies. They have hired a couple of dozen AI engineers in France in the preceding months, going from a team of 6 to 26. Now, RYTE is building and ramping up its technical team in the US with the same level of conviction.\nOpportunity\nJoin a well-funded AI health tech company at the forefront of using generative AI to help people and organizations make well-informed healthcare decisions\nRYTE is at a pivotal moment in writing the history of the company \u2013 it is putting its applications live and getting its first users \u2013 you get to join a company and be there at the beginning of its rapid growth\nThe global team and data model built over the last 3 years is very solid \u2013 they\u2019ve set up a great program for helping to develop AI use cases, models, and services to assist in making healthcare decisions\nRYTE\u2019s models are being developed for a variety of B2C, B2B, and B2D use cases that make the job very interesting, employing an extensive array of analytical capabilities, including name recognition and sentiment analysis\nTeams are in clusters of 9 with AI Team Leads allowing RYTE to scale effectively while focusing on a consistent set of tasks and priorities. You can focus on one thing, deliver, and feel the impact of the contributions you make.\nDirectly report to:\nVP of Artificial Intelligence (in Paris, France)\nCompany Size:\n120+ team members across the globe, including Canada, France, Kazakhstan, and the Philippines; and now growing its US presence\nLocation:\nUSA Remote to start; with relocation to Miami FL once offices are set up\nTravel:\nPossible travel in the US, to Kazakhstan (Nur-Sultan), Philippines (Manilla), Canada (Toronto), and France (Paris).\nUseful Links\nRYTE Website:\nhttps://ryte.ai/\nB2C Apps:\nSoon to be released in the US app stores.\nB2B/B2D Apps:\nIn active development.\nProcess\nRecruiter Interview:\nHigh-level 30-min review of aspirations, work experience, past successes\nInterview 1 with the VP of Artificial Intelligence and an AI Team Lead:\n60-90 minute video meeting\nInterview 2:\n30-45 minute video meeting\nOffer\nShow more\nShow less"
    },
    {
      "rank": 3,
      "job_id": 546,
      "job_title": "Senior Deep Learning Software Engineer, Algorithmic Model Optimization",
      "score": 0.28180127547707007,
      "job_description": "We are now looking for a Deep Learning Software Engineer, for Algorithmic Model Optimization!\nJoin our team of algorithmic model optimization experts and take part in unlocking the biggest potential for AI with generative models such as large language models (LLM) and diffusion models. As a Senior Deep Learning Software Engineer, you will be at the forefront of pushing the boundaries of these models and enabling their deployment at a larger scale with unmatched efficiency. We are developing an innovative software platform that will not only be utilized internally but also have a significant impact externally by enabling the creation of groundbreaking AI products. This is an exceptional opportunity for passionate software engineers like you, who have a strong background in Deep Learning, to join us in solving the most significant challenges in the field.\nYour role will be pivotal in our mission to maximize the potential of our rapidly expanding data center deployments. Additionally, you will play a crucial part in adopting a data-driven approach to hardware design and system software development. Collaboration is at the heart of what we do, and you will have the chance to work closely with a diverse range of teams at NVIDIA, including the Applied Deep Learning Research teams, CUDA Kernel and DL Framework development teams, and the Silicon Architecture Team. In this position, you will actively engage with internal stakeholders, users, and members of the open-source community. Your input will be vital in defining and implementing cutting-edge model optimization algorithms. The scope of your work will encompass researching and developing highly efficient search algorithms, defining public APIs, implementation, and various other software engineering tasks. We are seeking individuals who are as enthusiastic as we are about pushing the boundaries of AI and contributing to groundbreaking advancements in the field. If you are passionate about innovation, tackling complex DL problems, and working in a collaborative environment, this is the perfect opportunity for you. Join us, and together, we will shape the future of AI model optimization and its impact on the world.\nWhat You\u2019ll Be Doing\nPrototype and develop model optimization methods, and build a most impactful model optimization platform\nCollaborate with internal and external partners to accelerate the adoption of deep learning model optimization\nStay up to date with the latest research and innovations in generative AI and model optimization techniques\nAnalyze and optimize the theoretical and practical performance of DL models generated\nPublish findings in top AI conferences, and create Intellectual Property\nWhat We Need To See\nMasters, PhD, or equivalent experience in Computer Science, AI, Applied Math, or related field.\n2+ years of relevant work or research experience in Deep Learning.\nExcellent software design skills, including debugging, performance analysis, and test design\nStrong algorithms and programming fundamentals\nAbility to work independently, define project goals and scope, and run your own development effort\nGood communication, documentation habits, and interpersonal skills\nExperience with one or more: Python, C++, performance tuning\nWays To Stand Out From The Crowd\nContributions to PyTorch, JAX, or other Machine Learning Frameworks\nKnowledge of GPU architecture and compilation stack, and capability of understanding and debugging end-to-end performance\nFamiliarity with Nvidia\u2019s deep learning SDK such as TensorRT\nStrong understanding of deep learning algorithms and solutions\nStrong understanding of ML model optimization techniques such as quantization, pruning, distillation.\nIncreasingly known as \u201cthe AI computing company\u201d and widely considered to be one of the technology world\u2019s most desirable employers, NVIDIA offers highly competitive salaries and a comprehensive benefits package. Are you creative, motivated, and love a challenge? If so, we want to hear from you! Come, join our model optimization group, where you can help build real-time, cost-effective computing platforms driving our success in this exciting and rapidly growing field.\nThe base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.\nYou will also be eligible for equity and benefits .\nNVIDIA accepts applications on an ongoing basis.\nNVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.\nShow more\nShow less"
    },
    {
      "rank": 4,
      "job_id": 12866,
      "job_title": "Senior Software Engineer",
      "score": 0.28033111054580717,
      "job_description": "Were searching for a Senior Software Engineer, who can be based in our partners New York City office in a hybrid schedule.\nThe Senior Software Engineer position in the Data Strategy team at Guy Carpenter (\u201cGC\u201d) presents a chance to create and execute data products for the worlds biggest and most reputable reinsurance brokerage.\nData Strategy has a \u201cstart-up style\u201d mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the GC organization.\nThis innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.\nAs a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across GC and (2) driving the monetization of data via newly designed and existing products for GC\u2019s reinsurance clients.\nThe Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.\nRESPONSIBILITIES:\nWork with a product manager as technical lead of a team of :5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.\nManage junior data and web engineers, focusing on productivity, quality, and professional development.\nPartner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.\nEnforce strong development standards across the team through code reviews, automated testing, and monitoring.\nEstablish strong relationships with internal clients as an engineering representative for data strategy.\nContribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.\nPartner regularly improving engineering recruiting process for the required skillsets and resourcing demands.\nLearn the complex business of reinsurance to coach data technologists and execute the teams initiatives more effectively.\nDevelop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.\nInnovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.\nArchitect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.\nDesign solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.\nPerform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.\nDevelop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.\nQUALIFICATIONS:\n5-8+ years of relevant experience in data-focused software engineering\nMaster\u2019s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience.\nExperience working with Python-based server-side web frameworks like FastAPI or Django\nStrong knowledge of SQL and familiarity with the high-level properties of modern data stores.\nStrong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.\nExperience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.\n2+ years of data analysis, AI, or data science work.\nExperience with data cleaning, enrichment, and reporting to business users.\nExtensive experience with (py)Spark, Python, JSON, and SQL.\nExperience integrating data from semi-structured and unstructured sources.\nKnowledge of various industry-leading SQL and NoSQL database systems.\nExperience with or strong interest in learning about LLMs in a productized context.\nADDITIONAL QUALIFICATIONS:\nStrong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks.\nExperience with web scraping and crowdsourcing technologies.\nExperience with Databricks and optimizing Spark clusters.\nExperience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.\nExperience working with data visualization dashboarding tools (PowerBI, Tableau).\nInsurance domain knowledge or strong interest in developing it.\nExperience with the MS Azure cloud environment.\nRequirements\nMaster\u2019s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience.\n5-8+ years of relevant experience in data-focused software engineering.\n2+ years of data analysis, AI, or data science work.\nPython-based server-side web frameworks like FastAPI or Django.\nExtensive experience with (py)Spark, Python, JSON, and SQL\nData cleaning, enrichment, and reporting to business users\nSQL and NoSQL database systems\nSQL and familiarity with the high-level properties of modern data stores.\nData visualization dashboarding tools (PowerBI, Tableau).\nDatabricks and optimizing Spark clusters\nMS Azure cloud environment\nStrong interest in learning about LLMs (Large Language Models) in a productized context, entity resolution, streaming technologies, ELT/ETL frameworks, web scraping, crowdsourcing technologies, Databricks, and optimizing Spark clusters.\nGood interpersonal and communication skills.\nNice to have:\nArchitected web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.\nAdditional information:\nWork for a global company with excellent benefits and a dynamic culture.\nExcellent growth/advancement opportunity.\nWork?with collaborative successful colleagues who truly care about the work and each other while maintaining work life balance.\nA hybrid working arrangement, 3 days in office, 2 days working from home.\nShow more\nShow less"
    },
    {
      "rank": 5,
      "job_id": 13526,
      "job_title": "Senior Software Engineer",
      "score": 0.28033111054580717,
      "job_description": "Were searching for a Senior Software Engineer, who can be based in our partners New York City office in a hybrid schedule.\nThe Senior Software Engineer position in the Data Strategy team at Guy Carpenter (\u201cGC\u201d) presents a chance to create and execute data products for the worlds biggest and most reputable reinsurance brokerage.\nData Strategy has a \u201cstart-up style\u201d mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the GC organization.\nThis innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.\nAs a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across GC and (2) driving the monetization of data via newly designed and existing products for GC\u2019s reinsurance clients.\nThe Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.\nRESPONSIBILITIES:\nWork with a product manager as technical lead of a team of :5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.\nManage junior data and web engineers, focusing on productivity, quality, and professional development.\nPartner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.\nEnforce strong development standards across the team through code reviews, automated testing, and monitoring.\nEstablish strong relationships with internal clients as an engineering representative for data strategy.\nContribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.\nPartner regularly improving engineering recruiting process for the required skillsets and resourcing demands.\nLearn the complex business of reinsurance to coach data technologists and execute the teams initiatives more effectively.\nDevelop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.\nInnovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.\nArchitect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.\nDesign solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.\nPerform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.\nDevelop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.\nQUALIFICATIONS:\n5-8+ years of relevant experience in data-focused software engineering\nMaster\u2019s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience.\nExperience working with Python-based server-side web frameworks like FastAPI or Django\nStrong knowledge of SQL and familiarity with the high-level properties of modern data stores.\nStrong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.\nExperience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.\n2+ years of data analysis, AI, or data science work.\nExperience with data cleaning, enrichment, and reporting to business users.\nExtensive experience with (py)Spark, Python, JSON, and SQL.\nExperience integrating data from semi-structured and unstructured sources.\nKnowledge of various industry-leading SQL and NoSQL database systems.\nExperience with or strong interest in learning about LLMs in a productized context.\nADDITIONAL QUALIFICATIONS:\nStrong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks.\nExperience with web scraping and crowdsourcing technologies.\nExperience with Databricks and optimizing Spark clusters.\nExperience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.\nExperience working with data visualization dashboarding tools (PowerBI, Tableau).\nInsurance domain knowledge or strong interest in developing it.\nExperience with the MS Azure cloud environment.\nRequirements\nMaster\u2019s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience.\n5-8+ years of relevant experience in data-focused software engineering.\n2+ years of data analysis, AI, or data science work.\nPython-based server-side web frameworks like FastAPI or Django.\nExtensive experience with (py)Spark, Python, JSON, and SQL\nData cleaning, enrichment, and reporting to business users\nSQL and NoSQL database systems\nSQL and familiarity with the high-level properties of modern data stores.\nData visualization dashboarding tools (PowerBI, Tableau).\nDatabricks and optimizing Spark clusters\nMS Azure cloud environment\nStrong interest in learning about LLMs (Large Language Models) in a productized context, entity resolution, streaming technologies, ELT/ETL frameworks, web scraping, crowdsourcing technologies, Databricks, and optimizing Spark clusters.\nGood interpersonal and communication skills.\nNice to have:\nArchitected web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.\nAdditional information:\nWork for a global company with excellent benefits and a dynamic culture.\nExcellent growth/advancement opportunity.\nWork?with collaborative successful colleagues who truly care about the work and each other while maintaining work life balance.\nA hybrid working arrangement, 3 days in office, 2 days working from home.\nShow more\nShow less"
    },
    {
      "rank": 6,
      "job_id": 3185,
      "job_title": "Data Scientist",
      "score": 0.2799380672556284,
      "job_description": "Data is literally the new Oil\n- and our belief is that the future of energy requires data to thrive and adapt to the massive changes in the world.\nTo accomplish this goal of being the best energy data platform we are seeking a rockstar data scientist to join our dynamic team that is passionate about generating insights from numbers, text and images.\nThis role is ideal for someone who thrives in an innovative and fast-paced environment and is eager to contribute to the development of energy-efficient solutions.\nResponsibilities\nCollect and prepare data from multiple sources to ensure a robust and reliable data foundation\nAnalyze large sets of complex data to uncover hidden patterns and insights\nDevelop and select meaningful features to enhance model accuracy and efficiency\nDesign and implement predictive models and algorithms using machine learning techniques\nDevelop natural language understanding methods out of free-unstructured-text using entity extraction and sentiment analysis\nEnsure the quality and accuracy of models through rigorous testing and validation\nCollaborate with cross-functional teams to translate data insights into actionable strategies\nStay up-to-date with the latest advancements in machine learning and data science techniques\nRequirements\nBachelor\u2019s or Master\u2019s degree in Data Science, Computer Science, Statistics, or a related field\nAt least 2 years of experience in a data science or data engineering role\nProficiency in standard machine learning tools, with a strong preference for experience in Python libraries\nExperience with big data technologies such as Hadoop or Spark is a plus\nStrong analytical and problem-solving skills, with an ability to handle complex, multivariable analyses\nExcellent communication skills, both verbal and written\nShow more\nShow less"
    },
    {
      "rank": 7,
      "job_id": 904,
      "job_title": "Senior NLP Engineer (USA Remote)",
      "score": 0.27401972691611015,
      "job_description": "Are you a Senior NLP Engineer with in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts?\nRYTE, a breakthrough Artificial Intelligence health tech company is looking for Senior NLP Engineers who will contribute to pushing the boundaries of RYTE\u2019s natural language processing capabilities and driving innovation within the company\u2019s linguistic technology initiatives.\nAbout RYTE\nFinding the right physician, selecting the organization providing the most suitable service, and obtaining the most relevant health information, whether in the US or globally, can be complex and filled with uncertainty. Enter RYTE: an AI-driven platform designed to simplify this process. By analyzing data from millions of healthcare providers, experts, medical procedures, clinical outcomes, and a variety of other data points, RYTE offers users a comprehensive view of their options, uniquely tailored to their needs. It offers:\nPersonalized Recommendations: Based on your specific situation, RYTE's platform presents the best healthcare options for you, no matter where you are in the world.\nUnprecedented Insights: With billions of data points on countless medical professionals and facilities, its AI-driven software gives rankings and insights with metrics previously unavailable for decision-making.\nVersatile Applications: Launching for individuals seeking specialized care (B2C), with plans for the Pharmaceutical, Medtech, Health Insurance (B2B) and Doctor (B2D) markets, the RYTE platform caters to diverse needs.\nBehind RYTE is a dedicated team of top physicians, healthcare executives, data scientists, and AI specialists who have been hard at work since 2019. Their mission? To empower everyone, everywhere, with the data-driven insights required to make well-informed healthcare decisions.\nSenior NLP Engineer (USA Remote - Eastern Time)\nBase:\nExtremely competitive\nBonus:\nA generous year-end bonus, based on performance\nBenefits:\nFull benefits, including medical, dental, and vision insurance\nLocation:\nRemote in the USA\nPosition:\nFull-Time, Permanent\nTime Zone:\nMust be in a US city with the Eastern (EST) or Central (CST) Standard Time zone.\nAbout The Role\nAs part of the AI and data engineering department, you will work side to side with a team of AI engineers, architects and data scientists located in multiple countries (the US, France, and Kazakhstan) to perform research and development on AI-based technologies applied to Healthcare Analytics.\nThe Senior NLP Engineer plays a crucial role within the research and development team focused on linguistic technologies. The primary responsibility of this role is to design, develop, and enhance advanced NLP solutions to meet the company\u2019s needs across various domains, working with structured, semi-structured, and non-structured data coming from a wide variety of public and private data sources.\nThe role will be expected to contribute to the design, conception, creation, development, implementation, and testing of different NLP AI algorithms to help measure, map, correlate, disambiguate, and track the quality of RYTE\u2019s rich databases.\nThe Ideal Candidate\nThe ideal candidate will be able to take on a role that is \u201c20% Research / 70% Data Science / 10% MLOps\u201d.\nThe position requires in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts. They are NOT looking for a research scientist, but someone more interested in applying the \u201cstate of the art\u201d approach to long-term projects. You will be processing new data to solve a problem, evaluating the results, selecting an approach within 1-2 weeks, and then shipping your project. Your MLOps skills will be useful to understand the MLOps team\u2019s expectations and to help hand things over.\nWhat You\u2019ll Be Doing \u2013 Day-to-Day\nAs part of the AI and data engineering department, you will work side to side with a team of AI engineers, architects, and data scientists located in multiple countries to perform research and development on AI-based technologies applied to Healthcare Analytics.\nResearch and Development:\nDesign and develop advanced NLP models, such as entity disambiguation, text generation, machine translation, sentiment analysis that will form the core of our solutions.\nDefine appropriate datasets for language learning.\nExperiment with the latest advancements in NLP research and incorporate them into development projects.\nManage project timelines, milestones, and deliverables autonomously, ensuring timely and successful completion of projects.\nIdentify risks and potential roadblocks, and proactively develop strategies to mitigate them.\nOptimization and Enhancement:\nAnalyze and improve the performance of existing NLP models in terms of accuracy, speed and efficiency.\nOptimize text processing pipelines to handle large volumes of data.\nCollaboration:\nWork closely with other engineers, data scientists and researchers to solve complex natural language processing challenges.\nParticipate in meetings and discussions to share ideas, findings, and recommendations with internal stakeholders.\nValidation and Testing:\nDesign testing protocols to evaluate the quality and performance of NLP models.\nTrain the developed model and run evaluation experiments.\nStay updated on the latest trends and advancements in NLP by reading research papers, and tracking relevant open-source projects.\nTeam Mentorship:\nProvide mentorship and support to the NLP engineering team\u2019s intermediate and junior members, fostering a collaborative and innovative work environment.\nOffer constructive feedback, identify areas for improvement.\nAssist in designing and delivering training programs to enhance team member\u2019s technical skills, soft skills and domain knowledge.\nTutoring Interns:\nCollaborate with HR and hiring managers to evaluate resumes, conduct interviews and assess candidates\u2019 technical and cultural fit.\nMentoring of interns, ensuring they receive guidance and support throughout their internship period.\n\u2014\nWhy new role:\nRYTE is expanding its technical teams rapidly in various geographies. They have hired a couple of dozen AI engineers in France in the preceding months, going from a team of 6 to 26. Now, RYTE is building and ramping up its technical team in the US with the same level of conviction.\nOpportunity\nJoin a well-funded AI health tech company at the forefront of using generative AI to help people and organizations to make well-informed healthcare decisions\nRYTE is at a pivotal moment in writing the history of the company \u2013 it is putting its applications live and getting its first users \u2013 you get to join a company and be there at the beginning of its rapid growth\nThe global team and data model built over the last 3 years is very solid \u2013 they\u2019ve set up a great program for helping to develop AI use cases, models, and services to assist in making healthcare decisions\nRYTE\u2019s models are being developed for a variety of B2C, B2B, and B2D use cases that make the job very interesting, employing an extensive array of analytical capabilities, including name recognition and sentiment analysis\nTeams are in clusters of 10 allowing RYTE to scale effectively while focusing on a consistent set of tasks and priorities. You can focus on one thing, deliver, and feel the impact of the contributions you make.\nDirectly report to:\nVP of Artificial Intelligence, with Technical Lead\nCompany Size:\n120+ team members across the globe, including Canada, France, Kazakhstan, and Philippines; and now growing its US presence\nProcess\nRecruiter Interview: High-level 30-min review of aspirations, work experience, past successes\nInterview 1 with a Team Lead and Senior NLP Engineer: 60-90 minute video meeting\nInterview 2 with VP of Artificial Intelligence: 30-45 minute video meeting\nOffer\nShow more\nShow less"
    },
    {
      "rank": 8,
      "job_id": 8524,
      "job_title": "Principal Machine Learning Scientist",
      "score": 0.2678879408930386,
      "job_description": "DISCO is seeking a Principal Machine Learning Scientist to join our AI/ML team supporting our cutting-edge AI features in the domain of legal technology. The successful candidate will have a wide knowledge of techniques and theory in machine learning, with a special emphasis on deep learning. Most of our applications involve learning from document text, so NLP experience is of particular interest, especially experience with transfer learning using transformer models such as BERT and/or using Large Language Models.\nYour Impact\nAI/ML forms a core part of DISCO\u2019s brand and vision, and this position provides an opportunity to develop ideas that will transform the legal domain with significant benefits for the broader society.\nWhat You\u2019ll Do\nApply domain knowledge to conceptualize, design, and develop AI/ML applications based on loose product or operational requirements\nLead a team of machine learning scientists to:\nMonitor, maintain, and improve existing systems that leverage AI to give insight into relevance of documents for customer needs\nDesign and conduct experiments to assess the validity, quality, and usefulness of AI models\nDevelop proof-of-concept prototypes for AI models and techniques\nCollaborate with cross-functional teams to bring new AI features into production and/or integrate machine learning models into applications and services\nEffectively communicate complex technical concepts and AI solutions to non-technical stakeholders\nPropose and lead or execute applied research in topics relevant to the legal domain within Disco\u2019s broader AI strategy of developing tools to identify the legal salience of documents\nStay current with latest developments in AI/ML research\nDocument research ideas for publication in patents or conference proceedings\nFoster a culture of knowledge sharing within the data science team and wider organization through training sessions and workshops\nQualifications\nAdvanced Degree : Hold a PhD in Computer Science, Machine Learning, Mathematics, Physics or a related field.\nWork Experience: At least 5 years hands-on experience in artificial intelligence and machine learning, with a strong focus on generative AI applications.\nExpertise in AI Technologies: extensive experience in building and fine-tuning generative AI applications, including large language models. Proficiency in programming languages such as Python (preferred) and frameworks like PyTorch, TensorFlow, MxNet, or others is essential.\nNatural Language Processing (NLP) Proficiency: Showcase a deep understanding of NLP concepts, encompassing language modeling, text generation, sentiment analysis, and named entity recognition. Familiarity with cutting-edge language models like GPT, BERT, or XLNet is required.\nResearch Abilities: Demonstrated ability to conduct research and to stay updated with the latest developments in the field. Able to lead innovative research initiatives.\nLeadership & Innovation: Experience in leading teams, managing projects, and mentoring junior data scientists. Have a track record of leading teams in research, designing experiments, and evaluating results. We are looking for innovative problem solvers who can quickly grasp domain-driven problems and propose effective AI/ML solutions.\nEffective Communication: Possess strong written and verbal communication skills to collaborate seamlessly with diverse teams and articulate complex technical concepts to both technical and non-technical stakeholders.\nEven Better If You Have\nDemonstrable record of publications and/or patents indicating the ability to innovate and follow through on ideas\nExperience with cloud platforms and technologies for scalable model training and deployment\nExperience with parallel computing, distributed systems, or GPU acceleration\nFamiliarity with continuous integration and deployment (CI/CD) practices\nActual compensation is influenced by a wide array of factors including, but not limited to, skill set, level of experience, and specific office location. For New York City only, the minimum and maximum salary offered for this role is $220k-240k. Information on other compensation and benefits is available upon request.\nPerks of DISCO\nOpen, inclusive, and fun environment\nBenefits, including medical, dental and vision insurance, as well as 401(k)\nCompetitive salary plus RSUs\nFlexible PTO\nOpportunity to be a part of a company that is revolutionizing the legal industry\nGrowth opportunities throughout the company\nAbout DISCO\nDISCO provides a cloud-native, artificial intelligence-powered legal solution that simplifies ediscovery, legal document review and case management for enterprises, law firms, legal services providers and governments. Our scalable, integrated solution enables legal departments to easily collect, process and review enterprise data that is relevant or potentially relevant to legal matters.\nAre you ready to help us fulfill our mission to use technology to strengthen the rule of law? Join us!\nWe are an equal opportunity employer and value diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nShow more\nShow less"
    },
    {
      "rank": 9,
      "job_id": 596,
      "job_title": "GenAI Lead Data Scientist, Corporate Vice President",
      "score": 0.26679437399315475,
      "job_description": "Location Designation:\nHybrid\nWhen you join New York Life, you're joining a company that values career development, collaboration, innovation, and inclusiveness. We want employees to feel proud about being part of a company that is committed to doing the right thing. You'll have the opportunity to grow your career while developing personally and professionally through various resources and programs. New York Life is a relationship-based company and appreciates how both virtual and in-person interactions support our culture.\nThe\nCenter for Data Science and Artificial Intelligence (CDSAi)\nis the 70-person innovative corporate Analytics group within New York Life. We are a rapidly growing entrepreneurial department which designs, creates, and offers innovative data-driven solutions for many parts of the enterprise. For more information on CDSAi, please visit our website (https://www.newyorklife.com/careers/corporate/data-science). We have the freedom to explore external data sources and new statistical techniques and are excited about delivering a whole new generation of predictive analytics and artificial intelligence solutions.\nIn the 7 years of the existence of CDSAi we have built a lot of predictive modeling solutions that are being used by various areas in the company. We have also stood up a modern model deployment platform that allows our models to be accessed in real time or batch (via APIs) from any production system in the company.\nIn addition to several data science teams, CDSAi has a dedicated ML Ops team (for all infrastructure, data and model deployments), our own project management office, a model governance team, a development team (training, internships, media, events, other internal and external branding) and data science product managers.\nThis role will support our newly formed generative AI practice and report to the director of data science for generative AI. The person in the role is expected to have prior experience with creating generative AI solutions for practical business use cases. NYL's CEO has expressed that he wants the company to be a leader in generative AI in our industry. Hence, this role has the opportunity to help build out that vision. Since not every data science project may require generative AI, expert-level familiarity with regular statistical predictive modeling methodologies and practice is also essential.\nResponsibilities\nSupports and helps build a generative AI practice within CDSAi. This includes supporting use case development and associated stakeholder management in various business areas. It also means influencing infrastructure and tooling (in collaboration with ML Ops and IT), education of stakeholders and community, and governance (in collaboration with model governance team and Legal).\nManaging various stakeholders at the same level during solution design and project execution to successfully create solutions and deploy them into full production.\nIndependently leads and contributes to data analysis and modeling projects from project/sample design, business review meetings with internal and external clients deriving requirements/deliverables, reception and processing of data, performing analyses and modeling to final reports/presentations, communication of results and implementation support.\nDemonstrates to internal and external stakeholders how analytics can be implemented to maximize business benefits. Provides technical support, which includes strategic consulting, needs assessments, project scoping and the preparation/presentation of analytical proposals.\nUtilizes advanced statistical/AI techniques to create high-performing predictive models and other solutions to address business objectives and client needs. Tests new statistical and machine learning methods, software and data sources for continual improvement of quantitative solutions.\nImplements analytical models into production by collaborating with technology and ML Ops teams. Utilizes data visualization tools for model testing, modeling results and data patterns exhibition. Design performance metrics for model selection and performance monitoring.\nUtilizes data wrangling/data matching/ETL techniques while programming in several languages to explore a variety of data sources, gain data expertise, perform summary analyses and prepare modeling datasets. Deploys analytical solution in production systems.\nWorks closely with the business areas, IT, Legal, Government relations and several other groups in designing, building, and implementing these solutions.\nEvangelizes the use of data-based decision making and Analytics within New York Life.\nProactively and effectively communicates in various verbal and written formats with internal stakeholders on product design, data specification, model implementations, with partners on collaboration ideas and specifics, with internal clients and stakeholders on project/test results, opportunities, questions. Resolves problems and removes obstacles to timely and high-quality project completion.\nWorks collaboratively with project and product managers within CDSAi and on other teams.\nSupports internal events, expos, lunch & learns, etc. with displays and presentations.\nFollows industry trends in insurance and related data/analytics processes and businesses. Functions as the analytics expert in meetings with other internal areas and external vendors. Contributes ideas and actively participates in proof-of-concept tests of new processes and technologies.\nStays up to date on existing and proposed legislation and regulation (on federal and state level) that impact AI in underwriting. Assures compliance with regulatory and privacy requirements during design and implementation of modeling and analysis projects.\nTravels to events and vendor meetings as needed (\nMentors junior talent.\nRequired Qualifications.\nGraduate-level degree with concentration in a quantitative discipline such as statistics, computer science, mathematics, economics, or similar.\n4+ years of experience with predictive analytics using large and complex datasets.\nSubstantial expertise in both parametric statistical modeling techniques (linear regression, GLM, survival analysis, time series, etc.) and non-parametric techniques (GBM, NN, NLP).\nExpertise in regularization techniques (Ridge, Lasso, elastic nets), variable selection techniques, feature creation (transformation, binning, high level categorical reduction, etc.), validation (holdouts, CV, bootstrap) and model performance measures (may need to create new ones).\nSubstantial prior programming experience in languages such as R, Python, SPARK, SQL. Comfort with professional software development process and GitHub.\nDemonstrated expertise in deploying real-time models into production environments. This includes production-ready code, containerizing models, testing, and integration into business processes.\nDetailed recent NLP experience (basic techniques, large language models, transformers, etc.)\n2+ years of experience with generative AI solutions (both development and deployment/integration). Ideally this would include training, fine-tuning and prompt engineering.\nExperience with disparate impact testing vs. protected classes of statistical models is a plus.\nStrong verbal and written communications skills, listening and teamwork skills, and effective presentation skills. This is essential since you will have a lot of exposure to different internal groups (Business functions, Data, IT, Legal, Government Relations, etc.) as well as third-party data vendors and consultants.\nExperience with insurance or consumer financial data is a plus.\nStrong inclination for mentoring junior talent.\nLocation\n: 51 Madison Ave, Manhattan. Presence in the office is required Tuesday - Thursday\nSalary range:\n$132,500-$197,500\nOvertime eligible:\nExempt\nDiscretionary bonus eligible:\nYes\nSales bonus eligible:\nNo\nClick here to learn more about our benefits. Starting salary is dependent upon several factors including previous work experience, specific industry experience, and/or skills required.\nRecognized as one of\nFortune's\nWorld's Most Admired Companies, New York Life is committed to improving local communities through a culture of employee giving and volunteerism, supported by theFoundation.We're proud that due to our mutuality, we operate in the best interests of our policy owners. We invite you to bring your talents to New York Life, so we can continue to help families and businesses \"Be Good At Life.\" To learn more, please visit LinkedIn, our Newsroom and the Careers page of www.NewYorkLife.com.\nJob Requisition ID:89476\nPDN-9a32ea8f-59e8-4ef7-b0e5-33b1307b4e93\nShow more\nShow less"
    },
    {
      "rank": 10,
      "job_id": 2112,
      "job_title": "Distinguished Applied Researcher",
      "score": 0.2635182011446323,
      "job_description": "Job Description\nCenter 1 (19052), United States of America, McLean, Virginia\nDistinguished Applied Researcher\nOverview\nAt Capital One, we are creating trustworthy and reliable AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build.\nTeam Description\nThe AI Foundations team is at the center of bringing our vision for AI at Capital One to life. Our work touches every aspect of the research life cycle, from partnering with Academia to building production systems. We work with product, technology and business leaders to apply the state of the art in AI to our business.\nThis is an individual contributor (IC) role driving strategic direction through collaboration with Applied Science, Engineering and Product leaders across Capital One. As a well-respected IC leader, you will guide and mentor a team of applied scientists and their managers without being a direct people leader. You will be expected to be an external leader representing Capital One in the research community, collaborating with prominent faculty members in the relevant AI research community.\nIn This Role, You Will\nPartner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI-powered products that change how customers interact with their money.\nLeverage a broad stack of technologies \u2014 Pytorch, AWS Ultraclusters, Huggingface, Lightning, VectorDBs, and more \u2014 to reveal the insights hidden within huge volumes of numeric and textual data.\nBuild AI foundation models through all phases of development, from design through training, evaluation, validation, and implementation.\nEngage in high impact applied research to take the latest AI developments and push them into the next generation of customer experiences.\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals.\nThe Ideal Candidate\nYou love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it\u2019s about making the right decision for our customers.\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nCreative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You\u2019re not afraid to share a new idea.\nA leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You\u2019re passionate about talent development for your own team and beyond.\nTechnical. You\u2019re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing AI foundation models and solutions using open-source tools and cloud computing platforms.\nHas a deep understanding of the foundations of AI methodologies.\nExperience building large deep learning models, whether on language, images, events, or graphs, as well as expertise in one or more of the following: training optimization, self-supervised learning, robustness, explainability, RLHF.\nAn engineering mindset as shown by a track record of delivering models at scale both in terms of training data and inference volumes.\nExperience in delivering libraries, platform level code or solution level code to existing products.\nA professional with a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects.\nPossess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects.\nKey Responsibilities\nPartner with a cross-functional team of scientists, machine learning engineers, software engineers, and product managers to deliver AI-powered platforms and solutions that change how customers interact with their money.\nBuild AI foundation models through all phases of development, from design through training, evaluation, validation, and implementation\nEngage in high impact applied research to take the latest AI developments and push them into the next generation of customer experiences\nLeverage a broad stack of technologies \u2014 Pytorch, AWS Ultraclusters, Huggingface, Lightning, VectorDBs, and more \u2014 to reveal the insights hidden within huge volumes of numeric and textual data\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals\nBasic Qualifications\nPh.D. plus at least 4 years of experience in Applied Research or M.S. plus at least 6 years of experience in Applied Research\nPreferred Qualifications\nPhD in Computer Science, Machine Learning, Computer Engineering, Applied Mathematics, Electrical Engineering or related fields\nLLM\nPhD focus on NLP or Masters with 10 years of industrial NLP research experience\nCore contributor to team that has trained a large language model from scratch (10B + parameters, 500B+ tokens)\nNumerous publications at ACL, NAACL and EMNLP, Neurips, ICML or ICLR on topics related to the pre-training of large language models (e.g. technical reports of pre-trained LLMs, SSL techniques, model pre-training optimization)\nHas worked on an LLM (open source or commercial) that is currently available for use\nDemonstrated ability to guide the technical direction of a large-scale model training team\nExperience working with 500+ node clusters of GPUs Has worked on LLM scaled to 70B parameters and 1T+ tokens\nExperience with common training optimization frameworks (deep speed, nemo)\nBehavioral Models\nPhD focus on topics in geometric deep learning (Graph Neural Networks, Sequential Models, Multivariate Time Series)\nMember of technical leadership for model deployment for a very large user behavior model\nMultiple papers on topics relevant to training models on graph and sequential data structures at KDD, ICML, NeurIPs, ICLR\nWorked on scaling graph models to greater than 50m nodes Experience with large scale deep learning based recommender systems\nExperience with production real-time and streaming environments\nContributions to common open source frameworks (pytorch-geometric, DGL)\nProposed new methods for inference or representation learning on graphs or sequences\nWorked datasets with 100m+ users\nOptimization (Training & Inference)\nPhD focused on topics related to optimizing training of very large language models\n5+ years of experience and/or publications on one of the following topics: Model Sparsification, Quantization, Training Parallelism/Partitioning Design, Gradient Checkpointing, Model Compression\nFinetuning\nPhD focused on topics related to guiding LLMs with further tasks (Supervised Finetuning, Instruction-Tuning, Dialogue-Finetuning, Parameter Tuning)\nDemonstrated knowledge of principles of transfer learning, model adaptation and model guidance\nExperience deploying a fine-tuned large language model\nData Preparation\nNumerous Publications studying tokenization, data quality, dataset curation, or labeling\nLeading contributions to one or more large open source corpus (1 Trillion\nShow more\nShow less"
    }
  ],
  "embedding_results": [
    {
      "rank": 1,
      "job_id": 2112,
      "job_title": "Distinguished Applied Researcher",
      "score": 0.5286860787512477,
      "job_description": "Job Description\nCenter 1 (19052), United States of America, McLean, Virginia\nDistinguished Applied Researcher\nOverview\nAt Capital One, we are creating trustworthy and reliable AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build.\nTeam Description\nThe AI Foundations team is at the center of bringing our vision for AI at Capital One to life. Our work touches every aspect of the research life cycle, from partnering with Academia to building production systems. We work with product, technology and business leaders to apply the state of the art in AI to our business.\nThis is an individual contributor (IC) role driving strategic direction through collaboration with Applied Science, Engineering and Product leaders across Capital One. As a well-respected IC leader, you will guide and mentor a team of applied scientists and their managers without being a direct people leader. You will be expected to be an external leader representing Capital One in the research community, collaborating with prominent faculty members in the relevant AI research community.\nIn This Role, You Will\nPartner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI-powered products that change how customers interact with their money.\nLeverage a broad stack of technologies \u2014 Pytorch, AWS Ultraclusters, Huggingface, Lightning, VectorDBs, and more \u2014 to reveal the insights hidden within huge volumes of numeric and textual data.\nBuild AI foundation models through all phases of development, from design through training, evaluation, validation, and implementation.\nEngage in high impact applied research to take the latest AI developments and push them into the next generation of customer experiences.\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals.\nThe Ideal Candidate\nYou love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it\u2019s about making the right decision for our customers.\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nCreative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You\u2019re not afraid to share a new idea.\nA leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You\u2019re passionate about talent development for your own team and beyond.\nTechnical. You\u2019re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing AI foundation models and solutions using open-source tools and cloud computing platforms.\nHas a deep understanding of the foundations of AI methodologies.\nExperience building large deep learning models, whether on language, images, events, or graphs, as well as expertise in one or more of the following: training optimization, self-supervised learning, robustness, explainability, RLHF.\nAn engineering mindset as shown by a track record of delivering models at scale both in terms of training data and inference volumes.\nExperience in delivering libraries, platform level code or solution level code to existing products.\nA professional with a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects.\nPossess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects.\nKey Responsibilities\nPartner with a cross-functional team of scientists, machine learning engineers, software engineers, and product managers to deliver AI-powered platforms and solutions that change how customers interact with their money.\nBuild AI foundation models through all phases of development, from design through training, evaluation, validation, and implementation\nEngage in high impact applied research to take the latest AI developments and push them into the next generation of customer experiences\nLeverage a broad stack of technologies \u2014 Pytorch, AWS Ultraclusters, Huggingface, Lightning, VectorDBs, and more \u2014 to reveal the insights hidden within huge volumes of numeric and textual data\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals\nBasic Qualifications\nPh.D. plus at least 4 years of experience in Applied Research or M.S. plus at least 6 years of experience in Applied Research\nPreferred Qualifications\nPhD in Computer Science, Machine Learning, Computer Engineering, Applied Mathematics, Electrical Engineering or related fields\nLLM\nPhD focus on NLP or Masters with 10 years of industrial NLP research experience\nCore contributor to team that has trained a large language model from scratch (10B + parameters, 500B+ tokens)\nNumerous publications at ACL, NAACL and EMNLP, Neurips, ICML or ICLR on topics related to the pre-training of large language models (e.g. technical reports of pre-trained LLMs, SSL techniques, model pre-training optimization)\nHas worked on an LLM (open source or commercial) that is currently available for use\nDemonstrated ability to guide the technical direction of a large-scale model training team\nExperience working with 500+ node clusters of GPUs Has worked on LLM scaled to 70B parameters and 1T+ tokens\nExperience with common training optimization frameworks (deep speed, nemo)\nBehavioral Models\nPhD focus on topics in geometric deep learning (Graph Neural Networks, Sequential Models, Multivariate Time Series)\nMember of technical leadership for model deployment for a very large user behavior model\nMultiple papers on topics relevant to training models on graph and sequential data structures at KDD, ICML, NeurIPs, ICLR\nWorked on scaling graph models to greater than 50m nodes Experience with large scale deep learning based recommender systems\nExperience with production real-time and streaming environments\nContributions to common open source frameworks (pytorch-geometric, DGL)\nProposed new methods for inference or representation learning on graphs or sequences\nWorked datasets with 100m+ users\nOptimization (Training & Inference)\nPhD focused on topics related to optimizing training of very large language models\n5+ years of experience and/or publications on one of the following topics: Model Sparsification, Quantization, Training Parallelism/Partitioning Design, Gradient Checkpointing, Model Compression\nFinetuning\nPhD focused on topics related to guiding LLMs with further tasks (Supervised Finetuning, Instruction-Tuning, Dialogue-Finetuning, Parameter Tuning)\nDemonstrated knowledge of principles of transfer learning, model adaptation and model guidance\nExperience deploying a fine-tuned large language model\nData Preparation\nNumerous Publications studying tokenization, data quality, dataset curation, or labeling\nLeading contributions to one or more large open source corpus (1 Trillion\nShow more\nShow less"
    },
    {
      "rank": 2,
      "job_id": 596,
      "job_title": "GenAI Lead Data Scientist, Corporate Vice President",
      "score": 0.4825971362269624,
      "job_description": "Location Designation:\nHybrid\nWhen you join New York Life, you're joining a company that values career development, collaboration, innovation, and inclusiveness. We want employees to feel proud about being part of a company that is committed to doing the right thing. You'll have the opportunity to grow your career while developing personally and professionally through various resources and programs. New York Life is a relationship-based company and appreciates how both virtual and in-person interactions support our culture.\nThe\nCenter for Data Science and Artificial Intelligence (CDSAi)\nis the 70-person innovative corporate Analytics group within New York Life. We are a rapidly growing entrepreneurial department which designs, creates, and offers innovative data-driven solutions for many parts of the enterprise. For more information on CDSAi, please visit our website (https://www.newyorklife.com/careers/corporate/data-science). We have the freedom to explore external data sources and new statistical techniques and are excited about delivering a whole new generation of predictive analytics and artificial intelligence solutions.\nIn the 7 years of the existence of CDSAi we have built a lot of predictive modeling solutions that are being used by various areas in the company. We have also stood up a modern model deployment platform that allows our models to be accessed in real time or batch (via APIs) from any production system in the company.\nIn addition to several data science teams, CDSAi has a dedicated ML Ops team (for all infrastructure, data and model deployments), our own project management office, a model governance team, a development team (training, internships, media, events, other internal and external branding) and data science product managers.\nThis role will support our newly formed generative AI practice and report to the director of data science for generative AI. The person in the role is expected to have prior experience with creating generative AI solutions for practical business use cases. NYL's CEO has expressed that he wants the company to be a leader in generative AI in our industry. Hence, this role has the opportunity to help build out that vision. Since not every data science project may require generative AI, expert-level familiarity with regular statistical predictive modeling methodologies and practice is also essential.\nResponsibilities\nSupports and helps build a generative AI practice within CDSAi. This includes supporting use case development and associated stakeholder management in various business areas. It also means influencing infrastructure and tooling (in collaboration with ML Ops and IT), education of stakeholders and community, and governance (in collaboration with model governance team and Legal).\nManaging various stakeholders at the same level during solution design and project execution to successfully create solutions and deploy them into full production.\nIndependently leads and contributes to data analysis and modeling projects from project/sample design, business review meetings with internal and external clients deriving requirements/deliverables, reception and processing of data, performing analyses and modeling to final reports/presentations, communication of results and implementation support.\nDemonstrates to internal and external stakeholders how analytics can be implemented to maximize business benefits. Provides technical support, which includes strategic consulting, needs assessments, project scoping and the preparation/presentation of analytical proposals.\nUtilizes advanced statistical/AI techniques to create high-performing predictive models and other solutions to address business objectives and client needs. Tests new statistical and machine learning methods, software and data sources for continual improvement of quantitative solutions.\nImplements analytical models into production by collaborating with technology and ML Ops teams. Utilizes data visualization tools for model testing, modeling results and data patterns exhibition. Design performance metrics for model selection and performance monitoring.\nUtilizes data wrangling/data matching/ETL techniques while programming in several languages to explore a variety of data sources, gain data expertise, perform summary analyses and prepare modeling datasets. Deploys analytical solution in production systems.\nWorks closely with the business areas, IT, Legal, Government relations and several other groups in designing, building, and implementing these solutions.\nEvangelizes the use of data-based decision making and Analytics within New York Life.\nProactively and effectively communicates in various verbal and written formats with internal stakeholders on product design, data specification, model implementations, with partners on collaboration ideas and specifics, with internal clients and stakeholders on project/test results, opportunities, questions. Resolves problems and removes obstacles to timely and high-quality project completion.\nWorks collaboratively with project and product managers within CDSAi and on other teams.\nSupports internal events, expos, lunch & learns, etc. with displays and presentations.\nFollows industry trends in insurance and related data/analytics processes and businesses. Functions as the analytics expert in meetings with other internal areas and external vendors. Contributes ideas and actively participates in proof-of-concept tests of new processes and technologies.\nStays up to date on existing and proposed legislation and regulation (on federal and state level) that impact AI in underwriting. Assures compliance with regulatory and privacy requirements during design and implementation of modeling and analysis projects.\nTravels to events and vendor meetings as needed (\nMentors junior talent.\nRequired Qualifications.\nGraduate-level degree with concentration in a quantitative discipline such as statistics, computer science, mathematics, economics, or similar.\n4+ years of experience with predictive analytics using large and complex datasets.\nSubstantial expertise in both parametric statistical modeling techniques (linear regression, GLM, survival analysis, time series, etc.) and non-parametric techniques (GBM, NN, NLP).\nExpertise in regularization techniques (Ridge, Lasso, elastic nets), variable selection techniques, feature creation (transformation, binning, high level categorical reduction, etc.), validation (holdouts, CV, bootstrap) and model performance measures (may need to create new ones).\nSubstantial prior programming experience in languages such as R, Python, SPARK, SQL. Comfort with professional software development process and GitHub.\nDemonstrated expertise in deploying real-time models into production environments. This includes production-ready code, containerizing models, testing, and integration into business processes.\nDetailed recent NLP experience (basic techniques, large language models, transformers, etc.)\n2+ years of experience with generative AI solutions (both development and deployment/integration). Ideally this would include training, fine-tuning and prompt engineering.\nExperience with disparate impact testing vs. protected classes of statistical models is a plus.\nStrong verbal and written communications skills, listening and teamwork skills, and effective presentation skills. This is essential since you will have a lot of exposure to different internal groups (Business functions, Data, IT, Legal, Government Relations, etc.) as well as third-party data vendors and consultants.\nExperience with insurance or consumer financial data is a plus.\nStrong inclination for mentoring junior talent.\nLocation\n: 51 Madison Ave, Manhattan. Presence in the office is required Tuesday - Thursday\nSalary range:\n$132,500-$197,500\nOvertime eligible:\nExempt\nDiscretionary bonus eligible:\nYes\nSales bonus eligible:\nNo\nClick here to learn more about our benefits. Starting salary is dependent upon several factors including previous work experience, specific industry experience, and/or skills required.\nRecognized as one of\nFortune's\nWorld's Most Admired Companies, New York Life is committed to improving local communities through a culture of employee giving and volunteerism, supported by theFoundation.We're proud that due to our mutuality, we operate in the best interests of our policy owners. We invite you to bring your talents to New York Life, so we can continue to help families and businesses \"Be Good At Life.\" To learn more, please visit LinkedIn, our Newsroom and the Careers page of www.NewYorkLife.com.\nJob Requisition ID:89476\nPDN-9a32ea8f-59e8-4ef7-b0e5-33b1307b4e93\nShow more\nShow less"
    },
    {
      "rank": 3,
      "job_id": 11988,
      "job_title": "NLP Team Lead Engineer",
      "score": 0.47478978451679926,
      "job_description": "Are you an experienced NLP Engineer with in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts?\nRYTE, a breakthrough Artificial Intelligence health tech company is looking for an NLP Team Lead Engineer who will contribute to pushing the boundaries of RYTE\u2019s natural language processing capabilities and driving innovation within the company\u2019s linguistic technology initiatives.\nFinding the right physician, selecting the organization providing the most suitable service, and obtaining the most relevant health information, whether in the US or globally, can be complex and filled with uncertainty. Enter RYTE: an AI-driven platform designed to simplify this process. By analyzing data from millions of healthcare providers, experts, medical procedures, clinical outcomes, and a variety of other data points, RYTE offers users a comprehensive view of their options, uniquely tailored to their needs. It offers:\nPersonalized Recommendations: Based on your specific situation, RYTE's platform presents the best healthcare options for you, no matter where you are in the world.\nUnprecedented Insights: With billions of data points on countless medical professionals and facilities, its AI-driven software gives rankings and insights with metrics previously unavailable for decision-making.\nVersatile Applications: Launching for individuals seeking specialized care (B2C), with plans for the Pharmaceutical, Medtech, Health Insurance (B2B), and Doctor (B2D) markets, the RYTE platform caters to diverse needs.\nBehind RYTE is a dedicated team of top physicians, healthcare executives, data scientists, and AI specialists who have been hard at work since 2019. Their mission? To empower everyone, everywhere, with the data-driven insights required to make well-informed healthcare decisions.\nAI Team Lead / Senior NLP Engineer \u2013 Remote to Miami FL (Relocation Assistance Provided)\nBase:\nExtremely competitive\nBonus:\nA generous year-end bonus, based on performance\nBenefits:\nFull benefits, including medical, dental, and vision insurance\nLocation:\nRemote in the USA to start; then relocate to Miami FL in a reasonable time frame\nRelocation assistance:\nExpenses related to relocation will be provided as part of an offer\nPosition:\nFull-Time, Permanent\nRYTE is also hiring individual contributor Senior and Mid-level NLP Engineers, if you are interested please apply here.\nAbout The Role\nAs part of the AI and data engineering department, you will work side by side with a team of AI engineers, architects, and data scientists located in multiple countries (the US, France, and Kazakhstan) to perform research and development on AI-based technologies applied to Healthcare Analytics.\nThe NLP Team Lead Engineer plays a crucial role within the research and development team focused on linguistic technologies. The primary responsibility of this role is to design, develop, and enhance advanced NLP solutions to meet the company\u2019s needs across various domains, working with structured, semi-structured, and non-structured data coming from a wide variety of public and private data sources.\nThe role will be expected to contribute to the design, conception, creation, development, implementation, and testing of different NLP AI algorithms to help measure, map, correlate, disambiguate, and track the quality of RYTE\u2019s rich databases.\nThe Ideal Candidate\nThe ideal candidate will be able to take on a role that is \u201c20% Research / 60% Data Science / 20% MLOps\u201d.\nThe position requires in-depth expertise in computational linguistics, artificial intelligence, programming, and a strong understanding of fundamental NLP concepts. They are NOT looking for a research scientist, but someone more interested in applying the \u201cstate of the art\u201d approach to long-term projects. You will be processing new data to solve a problem, evaluating the results, selecting an approach within 1-2 weeks, and then shipping your project. Your MLOps skills will be needed to understand the MLOps team\u2019s expectations and properly hand things over.\nWhat You\u2019ll Be Doing \u2013 Day-to-Day\nAs part of the AI and data engineering department, you will work side by side with a team of AI engineers, architects, and data scientists located in multiple countries to perform research and development on AI-based technologies applied to Healthcare Analytics.\nResearch and Development:\nDesign and develop advanced NLP models, such as entity disambiguation, text generation, machine translation, and sentiment analysis that will form the core of our solutions.\nDefine appropriate datasets for language learning.\nExperiment with the latest advancements in NLP research and incorporate them into development projects.\nManage project timelines, milestones, and deliverables autonomously, ensuring timely and successful completion of projects.\nIdentify risks and potential roadblocks, and proactively develop strategies to mitigate them.\nOptimization and Enhancement:\nAnalyze and improve the performance of existing NLP models in terms of accuracy, speed, and efficiency.\nOptimize text processing pipelines to handle large volumes of data.\nCollaboration:\nWork closely with other engineers, data scientists, and researchers to solve complex natural language processing challenges.\nParticipate in meetings and discussions to share ideas, findings, and recommendations with internal stakeholders.\nValidation and Testing:\nDesign testing protocols to evaluate the quality and performance of NLP models.\nTrain the developed model and run evaluation experiments.\nStay updated on the latest trends and advancements in NLP by reading research papers, and tracking relevant open-source projects.\nTeam Leadership and Mentorship:\nProvide guidance, mentorship, and support to the engineering team, fostering a collaborative and innovative work environment.\nOffer constructive feedback, identify areas for improvement, and create personalized development plans.\nDesign and deliver training programs to enhance team members\u2019 technical skills, soft skills, and domain knowledge.\nExperience/Skills\nWhat RYTE is Looking For, In Order of Preference:\nAdvanced expertise in Natural Language Processing, with a deep understanding of language models / LLMs, syntax, semantics, etc.\nProficiency in machine learning techniques, including deep learning frameworks and algorithms (Pytorch, TensorFlow)\nStrong programming skills, preferably in languages such as Python, SQL\nExperience with NLP libraries and tools, like Transformers and Huggingface\nExperience in fine-tuning pre-trained large language models for specific tasks\nCharacter\nStrong communication skills to collaborate with cross-functional teams, able to:\nThis is a low-ego, collaborative environment \u2013 you will learn new things!\nMust be generous, willing to share what you know\nMust be highly motivated to work in a team environment where you both coach and learn from those around you\nOpenness to a multicultural work environment\nHumility, knowing that the field is moving every day and there is always something to learn from others\nEducation/Intelligence\nMaster\u2019s degree (or PhD) in Engineering, Data Science, or Computer Science\nSolid knowledge of data preprocessing, feature engineering, and model evaluation techniques\nExcellent problem-solving skills and the ability to address complex NLP challenges effectively\nCoachability\nMust have a love of learning and an openness to being challenged\nExpect to learn much from your peers & company stakeholders who are experts in their disciplines\nMust be willing to share your knowledge with the team and coach junior team members in the USA/France/Kazakhstan\nThe ideal candidate has a passion for AI, Healthcare, and building something that matters\nWhy new role:\nRYTE is expanding its technical teams rapidly in various geographies. They have hired a couple of dozen AI engineers in France in the preceding months, going from a team of 6 to 26. Now, RYTE is building and ramping up its technical team in the US with the same level of conviction.\nOpportunity\nJoin a well-funded AI health tech company at the forefront of using generative AI to help people and organizations make well-informed healthcare decisions\nRYTE is at a pivotal moment in writing the history of the company \u2013 it is putting its applications live and getting its first users \u2013 you get to join a company and be there at the beginning of its rapid growth\nThe global team and data model built over the last 3 years is very solid \u2013 they\u2019ve set up a great program for helping to develop AI use cases, models, and services to assist in making healthcare decisions\nRYTE\u2019s models are being developed for a variety of B2C, B2B, and B2D use cases that make the job very interesting, employing an extensive array of analytical capabilities, including name recognition and sentiment analysis\nTeams are in clusters of 9 with AI Team Leads allowing RYTE to scale effectively while focusing on a consistent set of tasks and priorities. You can focus on one thing, deliver, and feel the impact of the contributions you make.\nDirectly report to:\nVP of Artificial Intelligence (in Paris, France)\nCompany Size:\n120+ team members across the globe, including Canada, France, Kazakhstan, and the Philippines; and now growing its US presence\nLocation:\nUSA Remote to start; with relocation to Miami FL once offices are set up\nTravel:\nPossible travel in the US, to Kazakhstan (Nur-Sultan), Philippines (Manilla), Canada (Toronto), and France (Paris).\nUseful Links\nRYTE Website:\nhttps://ryte.ai/\nB2C Apps:\nSoon to be released in the US app stores.\nB2B/B2D Apps:\nIn active development.\nProcess\nRecruiter Interview:\nHigh-level 30-min review of aspirations, work experience, past successes\nInterview 1 with the VP of Artificial Intelligence and an AI Team Lead:\n60-90 minute video meeting\nInterview 2:\n30-45 minute video meeting\nOffer\nShow more\nShow less"
    },
    {
      "rank": 4,
      "job_id": 3102,
      "job_title": "Developer - Senior Data Engineer",
      "score": 0.47174453840248537,
      "job_description": "APPLICANTS MUST BE LOCAL TO NYC/NJ/SOUTHERN CONNECTICUT AREA - Driveable distance to NYC.\nJob Summary\nA Developer assists in designing, developing, and supporting applications. These applications include systems developed solely for the web environment as well as development efforts designed to web-enable end-user applications. This individual may also assist in the creation and ongoing management of corporate web sites and intranet communities. The Developer will have a thorough understanding of programming techniques and tools, web development, and system management tools.\nPrinciple Duties\nThe Sr. Data Engineer will play a pivotal role in designing, building and operationalizing data pipelines that feed the enterprise data ecosystem for a variety of multi-faceted analytics created by data consumers. The data engineer needs to guarantee compliance with data governance and data security requirements while creating, improving, and operationalizing integrated and reusable data pipelines. The data engineer will be measured on their ability to create repeatable, efficient, high-quality code, automation-friendly processes, and delivering work products quickly.\nYears Of Experience\nFive (5) years of progressive, responsible experience in the field of data processing, computer systems, and applications.\nOperations Specialty requires supervisory experience (5 years).\nGeneral Responsibilities\nLead construction, maintenance, & optimization of data pipelines.\nDrive Automation through effective metadata management, using innovative and modern tools, techniques, and architectures to improve productivity.\nLead renovation of the data management infrastructure to drive automation in data integration and management.\nCollaborate with multiple Analytics Center of Excellence teams and EIM team in refining their data requirements for various DnA initiatives and data consumption requirements.\nIdentify gaps in new data initiatives and how to address new data requirements.\nTransfer knowledge of data and/or domain understanding in addressing new data requirements.\nPropose appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques to optimize data requirements.\nWork with data governance teams to ensure data scientists and consumers use corresponding data responsibly through data governance and compliance initiatives.\nDesign and implement data quality monitoring systems, which includes source-to-target data validations as well as anomaly detection\nDevelop and understand all features of each a module and their impact on other modules.\nAnalyze and develop understanding of how data flows through the system and apply that knowledge to the current business model.\nIdentify and define system errors and/or deficiencies.\nLiaise with other developers (i.e: software, application, web, etc) to determine best path solutions and manage the priorities through collaboration with internal stakeholders.\nPlan and coordinate testing and implementation of system patches and upgrades leading a cross functional team of power users.\nExtract key business performance metrics.\nAnalyze user needs and software requirements to determine areas of opportunity for increased efficiencies.\nCreate written user documentation, instructions, and procedures for the purpose of training new employees and improving over-all user proficiency.\nEvaluate new technologies for potential implementation including development of business justification and project implementation planning, when appropriate.\nUtilizing in-house or external resources, manage the network and related hardware. Ensure that help-desk tasks are promptly addressed and resolved\nQualifications And Preferred Skills\n\u00e2\u0097? Bachelor's degree/master's degree/advanced degree in computer science, statistics, applied mathematics, data management, information systems, information science or related field\n\u00e2\u0097? Expertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies\n\u00e2\u0097? Preferred experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms\n\u00e2\u0097? Full Lifecycle Data Warehouse, Data Mart Development experience is a big plus.\n\u00e2\u0097? Agile Software development methodologies\n\u00e2\u0097? Preferred experience with any automation tool such as AutoSys, Cntl-M.\n\u00e2\u0097? Proficient in Microsoft Office (Required)\n\u00e2\u0097? Expert in Informatica PowerCenter, PL/SQL, SQL and additional programming languages such as Python, Java etc.\n\u00e2\u0097? Minimum 10 years of work experience in data management disciplines, including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.\n\u00e2\u0097? Minimum 2 years designing and implementing a fully operational production grade large scale data solution on Snowflake Data Warehouse.\n\u00e2\u0097? Minimum 10 years of hands on experience designing and implementing production grade data warehousing solutions on large scale databases such as SQL Server, Oracle or DB2\n\u00e2\u0097? 5+ years data pipeline development experience with Informatica Powercenter and IBM DataStage\n\u00e2\u0097? 3+ years of experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, others\n\u00e2\u0097? 3+ years of experience with Shell/Perl Scripting\n\u00e2\u0097? 5+ years of experience with popular database programming languages including SQL, PL/SQL\n(required), others for relational databases and certifications on upcoming NoSQL/Hadoop oriented databases (preferred) like MongoDB, Cassandra, others for nonrelational databases.\nEducation Level\nA Baccalaureate Degree from an accredited college or university with a major in Computer Science, Systems Engineering, applied Mathematics, Business Administration, Economics/Statistics, Telecommunications, Data Communications, or a related field of study; and\nFive (5) years of progressive, responsible experience in the field of data processing, computer systems, and applications.\nOperations Specialty requires supervisory experience (5 years).\nNetwork Services requires a telecommunications background and experience.\nBroad knowledge and expertise in the characteristics of computers, peripheral devices, communications systems and hardware capabilities, programming languages, E.D.P. applications, systems analysis methodology, data management and retrieval techniques; or\nA satisfactory equivalent combination of training, education, and experience.\nShow more\nShow less"
    },
    {
      "rank": 5,
      "job_id": 8524,
      "job_title": "Principal Machine Learning Scientist",
      "score": 0.4668370743437209,
      "job_description": "DISCO is seeking a Principal Machine Learning Scientist to join our AI/ML team supporting our cutting-edge AI features in the domain of legal technology. The successful candidate will have a wide knowledge of techniques and theory in machine learning, with a special emphasis on deep learning. Most of our applications involve learning from document text, so NLP experience is of particular interest, especially experience with transfer learning using transformer models such as BERT and/or using Large Language Models.\nYour Impact\nAI/ML forms a core part of DISCO\u2019s brand and vision, and this position provides an opportunity to develop ideas that will transform the legal domain with significant benefits for the broader society.\nWhat You\u2019ll Do\nApply domain knowledge to conceptualize, design, and develop AI/ML applications based on loose product or operational requirements\nLead a team of machine learning scientists to:\nMonitor, maintain, and improve existing systems that leverage AI to give insight into relevance of documents for customer needs\nDesign and conduct experiments to assess the validity, quality, and usefulness of AI models\nDevelop proof-of-concept prototypes for AI models and techniques\nCollaborate with cross-functional teams to bring new AI features into production and/or integrate machine learning models into applications and services\nEffectively communicate complex technical concepts and AI solutions to non-technical stakeholders\nPropose and lead or execute applied research in topics relevant to the legal domain within Disco\u2019s broader AI strategy of developing tools to identify the legal salience of documents\nStay current with latest developments in AI/ML research\nDocument research ideas for publication in patents or conference proceedings\nFoster a culture of knowledge sharing within the data science team and wider organization through training sessions and workshops\nQualifications\nAdvanced Degree : Hold a PhD in Computer Science, Machine Learning, Mathematics, Physics or a related field.\nWork Experience: At least 5 years hands-on experience in artificial intelligence and machine learning, with a strong focus on generative AI applications.\nExpertise in AI Technologies: extensive experience in building and fine-tuning generative AI applications, including large language models. Proficiency in programming languages such as Python (preferred) and frameworks like PyTorch, TensorFlow, MxNet, or others is essential.\nNatural Language Processing (NLP) Proficiency: Showcase a deep understanding of NLP concepts, encompassing language modeling, text generation, sentiment analysis, and named entity recognition. Familiarity with cutting-edge language models like GPT, BERT, or XLNet is required.\nResearch Abilities: Demonstrated ability to conduct research and to stay updated with the latest developments in the field. Able to lead innovative research initiatives.\nLeadership & Innovation: Experience in leading teams, managing projects, and mentoring junior data scientists. Have a track record of leading teams in research, designing experiments, and evaluating results. We are looking for innovative problem solvers who can quickly grasp domain-driven problems and propose effective AI/ML solutions.\nEffective Communication: Possess strong written and verbal communication skills to collaborate seamlessly with diverse teams and articulate complex technical concepts to both technical and non-technical stakeholders.\nEven Better If You Have\nDemonstrable record of publications and/or patents indicating the ability to innovate and follow through on ideas\nExperience with cloud platforms and technologies for scalable model training and deployment\nExperience with parallel computing, distributed systems, or GPU acceleration\nFamiliarity with continuous integration and deployment (CI/CD) practices\nActual compensation is influenced by a wide array of factors including, but not limited to, skill set, level of experience, and specific office location. For New York City only, the minimum and maximum salary offered for this role is $220k-240k. Information on other compensation and benefits is available upon request.\nPerks of DISCO\nOpen, inclusive, and fun environment\nBenefits, including medical, dental and vision insurance, as well as 401(k)\nCompetitive salary plus RSUs\nFlexible PTO\nOpportunity to be a part of a company that is revolutionizing the legal industry\nGrowth opportunities throughout the company\nAbout DISCO\nDISCO provides a cloud-native, artificial intelligence-powered legal solution that simplifies ediscovery, legal document review and case management for enterprises, law firms, legal services providers and governments. Our scalable, integrated solution enables legal departments to easily collect, process and review enterprise data that is relevant or potentially relevant to legal matters.\nAre you ready to help us fulfill our mission to use technology to strengthen the rule of law? Join us!\nWe are an equal opportunity employer and value diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nShow more\nShow less"
    }
  ]
}